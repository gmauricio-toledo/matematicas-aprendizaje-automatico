{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gmauricio-toledo/matematicas-aprendizaje-automatico/blob/main/Notebooks/MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/DCDPUAEM/DCDP/blob/main/04%20Deep%20Learning/notebooks/01-MLP-MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "OCYJbEwVkjda"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "‚úÖ Cuando se entrenan redes neuronales es recomendable conectar la notebook en modo GPU\n",
        "\n",
        "Entorno de ejecuci√≥n ‚Üí Cambiar tipo de entorno de ejecuci√≥n\n",
        "\n",
        "Algunas consideraciones:\n",
        "\n",
        "* No dejar la notebook conectada sin actividad ya que Colab penaliza esto al asignar un entorno con GPU.\n",
        "* No pedir el entorno con GPU si no se va a usar."
      ],
      "metadata": {
        "id": "GFJ63s_YhFD7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recuerda la simbolog√≠a de las secciones:\n",
        "\n",
        "* üîΩ Esta secci√≥n no forma parte del proceso usual de Machine Learning. Es una exploraci√≥n did√°ctica de alg√∫n aspecto del funcionamiento del algoritmo.\n",
        "* ‚ö° Esta secci√≥n incluye t√©cnicas m√°s avanzadas destinadas a optimizar o profundizar en el uso de los algoritmos.\n",
        "* ‚≠ï Esta secci√≥n contiene un ejercicio o pr√°ctica a realizar. A√∫n si no se establece una fecha de entrega, es muy recomendable realizarla para practicar conceptos clave de cada tema."
      ],
      "metadata": {
        "id": "i5RvSZFi--p3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejemplo ilustrativo 1: Clasificaci√≥n en $\\mathbb{R}^2$\n",
        "\n",
        "En este ejemplo veremos una tarea de clasificaci√≥n y, por medio de las capas ocultas, veremos el proceso de extraci√≥n de features de una red neuronal"
      ],
      "metadata": {
        "id": "6gWvhT-JE-xt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Funci√≥n para generar puntos en brazos de espirales en $\\mathbb{R}^2$"
      ],
      "metadata": {
        "id": "R-x6x5SbYnzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def make_spiral_dataset(n_classes=2, points_per_arm=100,\n",
        "                        noise=0.1, screw=0.01,\n",
        "                        gap=0.1,\n",
        "                        radius=1, num_arms=6):\n",
        "    X = np.zeros((num_arms*points_per_arm,2),dtype=np.float32)\n",
        "    y = np.zeros((num_arms*points_per_arm,),dtype=np.int32)\n",
        "\n",
        "    for k in range(num_arms):\n",
        "        rs = np.sort(np.random.uniform(0,radius,size=points_per_arm)) + gap\n",
        "        theta = 0.5 + 2*k*np.pi/num_arms\n",
        "        increments = np.array([screw*k for k in range(points_per_arm)])\n",
        "        thetas = theta + increments + np.random.uniform(0,noise,size=points_per_arm)\n",
        "        X[k*points_per_arm:(k+1)*points_per_arm,:] = np.array([rs*np.cos(thetas),rs*np.sin(thetas)]).T\n",
        "        y[k*points_per_arm:(k+1)*points_per_arm] = np.array([k%n_classes]*points_per_arm)\n",
        "\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "7aHpAU2KYirR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplo 1"
      ],
      "metadata": {
        "id": "b9PrJ8g0f1Qo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = make_spiral_dataset(points_per_arm=400,\n",
        "                           noise=0.3,\n",
        "                           screw=0.01,\n",
        "                           radius=2,\n",
        "                           gap=0.2,\n",
        "                           num_arms=6,\n",
        "                           n_classes=6\n",
        "                           )\n",
        "\n",
        "plt.figure()\n",
        "plt.axhline(0, color='black')\n",
        "plt.axvline(0, color='black')\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, alpha=0.5)\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eTkP1jPZOSRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Input\n",
        "from keras.regularizers import l2\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_classes = to_categorical(y,num_classes=6)\n",
        "\n",
        "# # 1. PREPROCESAMIENTO\n",
        "# scaler = StandardScaler()\n",
        "# X = scaler.fit_transform(X)\n",
        "\n",
        "# 2. Split manual con stratify (m√°s control)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y_classes, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# 3. Red balanceada: capacidad suficiente + regularizaci√≥n moderada\n",
        "model = Sequential([\n",
        "    Input(shape=(2,)),\n",
        "    Dense(256, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    Dropout(0.3),\n",
        "    Dense(256, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    Dropout(0.3),\n",
        "    Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    Dropout(0.3),\n",
        "    Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    Dropout(0.2),\n",
        "    Dense(64, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(8, activation='relu'),\n",
        "    Dense(2, activation='linear', name='bottleneck_2d'),  # Cuello de botella\n",
        "    Dense(6, activation='softmax')\n",
        "])\n",
        "\n",
        "# 4. Optimizer con learning rate controlado\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=optimizer,\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 5. Callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=20,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=10,\n",
        "        min_lr=1e-7,\n",
        "        verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "# 6. Entrenamiento\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=200,\n",
        "    batch_size=64,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "RvjHSwS4DQU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss_train = history.history['loss']\n",
        "loss_val = history.history['val_loss']\n",
        "acc_train = history.history['accuracy']\n",
        "acc_val = history.history['val_accuracy']\n",
        "epochs = range(1,len(loss_train)+1)\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
        "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
        "plt.title('Loss')\n",
        "plt.xlabel(\"√âpoca\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs, acc_train, 'g', label='Training accuracy')\n",
        "plt.plot(epochs, acc_val, 'b', label='validation accuracy')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel(\"√âpoca\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZeMBfa2NDdTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_val, y_val)"
      ],
      "metadata": {
        "id": "M37e3FZbD5QP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Modelo para extraer las features 2d de la pen√∫ltima capa\n",
        "feature_model = Model(inputs=model.layers[0].input,\n",
        "                      outputs=model.get_layer('bottleneck_2d').output)\n",
        "features_2d = feature_model.predict(X_train)\n",
        "\n",
        "plt.figure(figsize=(15, 8))\n",
        "plt.subplot(1,2,1)\n",
        "for i in range(6):\n",
        "    plt.scatter(X_train[y_train[:,i]==1, 0],\n",
        "                X_train[y_train[:,i]==1, 1],\n",
        "                label=f\"Clase {i}\")\n",
        "plt.axhline(0, color='black')\n",
        "plt.axvline(0, color='black')\n",
        "plt.legend()\n",
        "plt.subplot(1,2,2)\n",
        "for i in range(6):\n",
        "    plt.scatter(features_2d[y_train[:,i]==1, 0],\n",
        "                features_2d[y_train[:,i]==1, 1],\n",
        "                label=f\"Clase {i}\")\n",
        "plt.axhline(0, color='black')\n",
        "plt.axvline(0, color='black')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "91Vq_THKQeLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplo 2"
      ],
      "metadata": {
        "id": "g5hs2ZgqgH_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X, y = make_spiral_dataset(points_per_arm=400,\n",
        "                           noise=0.12,\n",
        "                           screw=0.01,\n",
        "                           radius=2,\n",
        "                           num_arms=8,\n",
        "                           n_classes=2\n",
        "                           )\n",
        "plt.figure()\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7_KGIGyIE-KG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos una red neuronal"
      ],
      "metadata": {
        "id": "geynzZAGKPeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Input\n",
        "from keras.regularizers import l2\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# # 1. PREPROCESAMIENTO\n",
        "# scaler = StandardScaler()\n",
        "# X = scaler.fit_transform(X)\n",
        "\n",
        "# 2. Split con stratify\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# 3. Modelo MLP\n",
        "model = Sequential([\n",
        "    Input(shape=(2,)),\n",
        "    Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    Dropout(0.2),\n",
        "    Dense(16, activation='relu',name='features_16d'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# 4. Optimizer con learning rate controlado\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=optimizer,\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 5. Callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=20,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=10,\n",
        "        min_lr=1e-7,\n",
        "        verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "# 6. Entrenamiento\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=200,\n",
        "    batch_size=64,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "LpvhJODWXmyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss_train = history.history['loss']\n",
        "loss_val = history.history['val_loss']\n",
        "acc_train = history.history['accuracy']\n",
        "acc_val = history.history['val_accuracy']\n",
        "epochs = range(1,len(loss_train)+1)\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
        "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
        "plt.title('Loss')\n",
        "plt.xlabel(\"√âpoca\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs, acc_train, 'g', label='Training accuracy')\n",
        "plt.plot(epochs, acc_val, 'b', label='validation accuracy')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel(\"√âpoca\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p-GY3UREYo10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_val, y_val)"
      ],
      "metadata": {
        "id": "6Lb9tV30GdBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos el modelo que extrae las features de la √∫ltima capa oculta"
      ],
      "metadata": {
        "id": "XgnNHxl8iBX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "\n",
        "# Extrae features de 16D\n",
        "feature_model = Model(inputs=model.layers[0].input,\n",
        "                      outputs=model.get_layer('features_16d').output)\n",
        "features_16d = feature_model.predict(X_train)"
      ],
      "metadata": {
        "id": "AVa_VvpmHr5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "from umap import UMAP\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Reduce a 2D para visualizar\n",
        "pca = PCA(n_components=2)\n",
        "features_2d_pca = pca.fit_transform(features_16d)\n",
        "\n",
        "umap = UMAP(n_components=2)\n",
        "features_2d_umap = umap.fit_transform(features_16d)\n",
        "\n",
        "# Graficamos\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(features_2d_pca[y_train==0, 0], features_2d_pca[y_train==0, 1],\n",
        "            c='blue', alpha=0.6, label='Clase 0')\n",
        "plt.scatter(features_2d_pca[y_train==1, 0], features_2d_pca[y_train==1, 1],\n",
        "            c='red', alpha=0.6, label='Clase 1')\n",
        "plt.xlabel('PC1')\n",
        "plt.ylabel('PC2')\n",
        "plt.title('Features 16D proyectadas a 2D con PCA')\n",
        "plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(features_2d_umap[y_train==0, 0], features_2d_umap[y_train==0, 1],\n",
        "            c='blue', alpha=0.6, label='Clase 0')\n",
        "plt.scatter(features_2d_umap[y_train==1, 0], features_2d_umap[y_train==1, 1],\n",
        "            c='red', alpha=0.6, label='Clase 1')\n",
        "plt.xlabel('UMAP1')\n",
        "plt.ylabel('UMAP2')\n",
        "plt.title('Features 16D proyectadas a 2D con UMAP')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jg2T66-3Gf6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejemplo Ilustrativo 2: Aproximando funciones $f:\\mathbb{R}^n\\rightarrow\\mathbb{R}^m$"
      ],
      "metadata": {
        "id": "hlil_ODV9qow"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bajamos una funci√≥n para graficar con plotly en 3D en HTML"
      ],
      "metadata": {
        "id": "NQ6CBighMnXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://raw.githubusercontent.com/gmauricio-toledo/tda-gdl/main/scatterplot3dHTML.py\n",
        "\n",
        "from scatterplot3dHTML import scatter_plot_3d_plotly"
      ],
      "metadata": {
        "id": "q7aD2cG0MjiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definamos una funci√≥n $f:\\mathbb{R}^2\\rightarrow\\mathbb{R}$"
      ],
      "metadata": {
        "id": "VV2RdidWKsRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import sin, cos\n",
        "\n",
        "# EJEMPLO 1: Gaussiana modulada con oscilaci√≥n radial\n",
        "# def f(x, y):\n",
        "#     r = np.sqrt(x**2 + y**2)\n",
        "#     return np.exp(-r**2 / 4) * np.cos(2*r)\n",
        "\n",
        "# EJEMPLO 2: Egg Crate\n",
        "def f(x, y):\n",
        "    return sin(x) * sin(y) + 0.1*(x**2 + y**2)"
      ],
      "metadata": {
        "id": "0GGemqlnDjZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generamos el conjunto de datos sampleando puntos sobre la superficie $z=f(x,y)$"
      ],
      "metadata": {
        "id": "p3ApwIrzLkU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generar dataset\n",
        "N = 5000\n",
        "X = np.zeros((N, 2))\n",
        "Y = np.zeros(N)\n",
        "\n",
        "for i in range(N):\n",
        "    x = np.random.uniform(-4, 4)\n",
        "    y = np.random.uniform(-4, 4)\n",
        "    X[i, :] = [x, y]\n",
        "    Y[i] = f(x, y)\n",
        "\n",
        "# Graficar el dataset\n",
        "puntos3d = np.array([X[:, 0], X[:, 1], Y]).T\n",
        "print(puntos3d.shape)\n",
        "\n",
        "scatter_plot_3d_plotly(X=puntos3d,\n",
        "                       filename='MLP-aproximation-dataset (Egg Crate).html',\n",
        "                       fig_title='MLP aproximation of a function\\nEgg Crate')"
      ],
      "metadata": {
        "id": "Pq9J8DDPLkGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dividimos en entrenamiento y prueba"
      ],
      "metadata": {
        "id": "dgg-QfMDMJo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"X_val shape: {X_val.shape}\")\n",
        "print(f\"y_val shape: {y_val.shape}\")"
      ],
      "metadata": {
        "id": "7Qtl6SfL8pL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Input\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "def crear_mlp(input_dim=2, hidden_units=64, n_hidden_layers=2, output_dim=1,\n",
        "              activation='tanh'):\n",
        "    \"\"\"\n",
        "    Crea un MLP para aproximaci√≥n de funciones\n",
        "\n",
        "    Args:\n",
        "        input_dim: dimensi√≥n de entrada (2 para f:R^2->R)\n",
        "        hidden_units: n√∫mero de neuronas por capa oculta\n",
        "        n_hidden_layers: n√∫mero de capas ocultas\n",
        "        output_dim: dimensi√≥n de salida (1)\n",
        "        activation: funci√≥n de activaci√≥n œÉ (debe ser no-polinomial)\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Input(shape=(input_dim,)))\n",
        "    # Primera capa oculta\n",
        "    model.add(Dense(hidden_units, activation=activation))\n",
        "\n",
        "    # Capas ocultas adicionales\n",
        "    for _ in range(n_hidden_layers - 1):\n",
        "        model.add(Dense(hidden_units, activation=activation))\n",
        "\n",
        "    # Capa de salida (sin activaci√≥n, seg√∫n la teor√≠a del MLP)\n",
        "    model.add(Dense(output_dim, activation='linear'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Crear el modelo\n",
        "model = crear_mlp(input_dim=2, hidden_units=64, n_hidden_layers=2)\n",
        "\n",
        "# Compilar\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='mse',  # Mean Squared Error para regresi√≥n\n",
        "    metrics=['mae']  # Mean Absolute Error\n",
        ")\n",
        "\n",
        "# Ver arquitectura\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Ddu1VkT89JmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compilamos y entrenamos"
      ],
      "metadata": {
        "id": "52AgRc_wMZRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss='mse',\n",
        "    optimizer='adam',\n",
        "    metrics=['mae']\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=15,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=10,\n",
        "        min_lr=1e-7,\n",
        "        verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=200,\n",
        "    batch_size=64,\n",
        "    verbose=1,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "id": "vJK771O5MZ7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss_train = history.history['loss']\n",
        "loss_val = history.history['val_loss']\n",
        "acc_train = history.history['mae']\n",
        "acc_val = history.history['val_mae']\n",
        "epochs = range(1,len(loss_train)+1)\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
        "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
        "plt.title('Loss')\n",
        "plt.xlabel(\"√âpoca\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs, acc_train, 'g', label='Training MAE')\n",
        "plt.plot(epochs, acc_val, 'b', label='validation MAE')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel(\"√âpoca\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bKdhdqLJ9ikF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hacemos un grid para graficar la superficie encontrada"
      ],
      "metadata": {
        "id": "eUQCvoI2PXfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Hacemos el conjunto de datos de entrenamiento {(x,y,f(x,y))}\n",
        "train_dataset = np.concatenate((X_train,y_train.reshape(-1,1)),axis=1)\n",
        "\n",
        "# Hacemos un grid de [-4,4]x[-4,4] y evaluamos la funci√≥n obtenida en cada punto\n",
        "x1, x2 = np.meshgrid(np.linspace(-4,4,100),np.linspace(-4,4,100))\n",
        "y_pred = model.predict(np.array([x1.flatten(),x2.flatten()]).T)\n",
        "grid_dataset = np.concatenate((np.array([x1.flatten(),x2.flatten()]).T,y_pred),axis=1)\n",
        "\n",
        "# Juntamos el dataset de entrenamiento y la superficie aproximada\n",
        "total_dataset = np.concatenate((train_dataset,grid_dataset))\n",
        "print(total_dataset.shape)\n",
        "# A√±adimos etiquetas para identificar los puntos de entrenamiento y la superficie obtenida\n",
        "labels = np.zeros(shape=(total_dataset.shape[0],))\n",
        "labels[:train_dataset.shape[0]] = 1\n",
        "print(labels.shape)"
      ],
      "metadata": {
        "id": "j6cHmOPJAXGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graficamos y guardamos en HTML"
      ],
      "metadata": {
        "id": "0jweIwvhP3v1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hover_info = ['Train dataset' if k==1 else 'Aproximation' for k in labels]\n",
        "\n",
        "scatter_plot_3d_plotly(X=total_dataset,\n",
        "                       y=labels,\n",
        "                       hover_info=hover_info,\n",
        "                       filename='MLP-aproximation (Egg Crate).html',\n",
        "                       fig_title='MLP aproximation of a function\\nEgg Crate')"
      ],
      "metadata": {
        "id": "cXOrM_NbCDBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Redes Neuronales MLP para clasificaci√≥n\n",
        "\n",
        "<img align=\"center\" width=\"50%\" src=\"https://github.com/DCDPUAEM/DCDP/blob/main/04%20Deep%20Learning/img/mlp.png?raw=1\"/>\n",
        "\n",
        "Ahora usaremos una red neuronal de tipo **MultiLayer Perceptron (MLP)** para el problema de clasificaci√≥n en el dataset MNIST.\n",
        "\n",
        "Veremos que con una red neuronal podremos entrenar un modelo para la clasificaci√≥n de este dataset usando todas las features sin mucho problema.\n",
        "\n",
        "---\n",
        "\n",
        "Recordemos el mejor modelo de Machine Learning cl√°sico que hemos obtenido:\n",
        "\n",
        "<center>\n",
        "<p><img src=\"https://drive.google.com/uc?id=1XY3iypQcSR868H7xFBilyxuzsJTzed4g\" width=\"500\" /></p>\n",
        "</center>\n",
        "\n",
        "Este modelo era dif√≠cil de entrenar en cuesti√≥n de la duraci√≥n del entrenamiento y requiri√≥ una busqueda exhaustiva de par√°metros.\n",
        "\n",
        "Con PCA (50-60 componentes principales) y SVM estabamos alrededor de 97% en las m√©tricas."
      ],
      "metadata": {
        "id": "jVMPmLi1VBRV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Benchmarks para el dataset MNIST\n",
        "\n",
        "1. **No Routing Needed Between Capsules**, 2020. *Accuracy: 99.87%*\n",
        "\n",
        "    Modelo de redes CNN con Homogeneous Vector Capsules (HVCs) que modifican el flujo de datos entre capas. [Art√≠culo](https://arxiv.org/abs/2001.09136), [c√≥digo](https://github.com/AdamByerly/BMCNNwHFCs).\n",
        "\n",
        "2. **An Ensemble of Simple Convolutional Neural Network Models for MNIST Digit Recognition**, 2020. *Accuracy: 99.87%*\n",
        "\n",
        "    Modelo de ensamble de redes CNN [Art√≠culo](https://arxiv.org/abs/2008.10400), [c√≥digo](https://github.com/ansh941/MnistSimpleCNN)."
      ],
      "metadata": {
        "id": "VU2YX1qiLBpd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. El conjunto de datos"
      ],
      "metadata": {
        "id": "QqvYSnkjVIzR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observar que, ahora s√≠, usamos todo el conjunto de datos completo."
      ],
      "metadata": {
        "id": "_d9wyeG1tpKA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyilk52n8rbV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# Load MNIST handwritten digit data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")\n",
        "\n",
        "y_test_original = y_test.copy()  # Hacemos una copia del 'y_test', la usaremos al final"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recordar que tenemos que dividir en tres conjuntos de entrenamiento: train, validation y test.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1Ts1ZZlHl1qTdkD_FZ2uvi9wkJtuTNH8M\" style=\"width: 60%\">\n",
        "</center>"
      ],
      "metadata": {
        "id": "-VtlF5rZwG2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,\n",
        "                                                  test_size=0.15,\n",
        "                                                  stratify=y_train,  # RECORDAR LA ESTRATIFIACI√ìN\n",
        "                                                  random_state=894)\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"X_val shape: {X_val.shape}\")\n",
        "print(f\"y_val shape: {y_val.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")"
      ],
      "metadata": {
        "id": "_APG4_h_fzEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos que esto no afecta a las imagenes:"
      ],
      "metadata": {
        "id": "1LJ5JTw65bJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "# Escogemos algunos √≠ndices:\n",
        "idxs = np.random.choice(range(X_train.shape[0]),size=3,replace=False)\n",
        "\n",
        "# Hacemos 3 tipos de reescalamiento:\n",
        "X_minmax = MinMaxScaler().fit_transform(X_train[idxs,:].reshape(-1,28*28))\n",
        "X_std = StandardScaler().fit_transform(X_train[idxs,:].reshape(-1,28*28))\n",
        "X_scl = X_train[idxs,:].reshape(-1,28*28)/255.\n",
        "\n",
        "# T√≠tulos para cada fila\n",
        "row_titles = [\n",
        "    \"Im√°genes originales\",\n",
        "    \"MinMaxScaler (por feature)\",\n",
        "    \"StandardScaler (por feature)\",\n",
        "    \"Reescalado [0, 1] (x/255)\"\n",
        "]\n",
        "\n",
        "# Graficamos:\n",
        "fig, axs = plt.subplots(ncols=3, nrows=4, sharex=False,\n",
        "                       sharey=True, figsize=(6, 9))\n",
        "for i, idx in enumerate(idxs):\n",
        "\t# Fila 0: Originales\n",
        "\taxs[0,i].imshow(X_train[idx], cmap='plasma')\n",
        "\taxs[0,i].axis('off')\n",
        "\n",
        "\t# Fila 1: MinMax\n",
        "\taxs[1,i].imshow(X_minmax[i].reshape(28,28), cmap='plasma')\n",
        "\taxs[1,i].axis('off')\n",
        "\n",
        "\t# Fila 2: StandardScaler\n",
        "\taxs[2,i].imshow(X_std[i].reshape(28,28), cmap='plasma')\n",
        "\taxs[2,i].axis('off')\n",
        "\n",
        "\t# Fila 3: Reescalado manual\n",
        "\taxs[3,i].imshow(X_scl[i].reshape(28,28), cmap='plasma')\n",
        "\taxs[3,i].axis('off')\n",
        "\tif i == 1:\n",
        "\t\tfor j in range(4):\n",
        "\t\t\taxs[j,i].set_title(row_titles[j],fontsize=10)\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "1hpMz6rz5e6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîµ Esto nos da una idea del data leakage"
      ],
      "metadata": {
        "id": "VB07z5LuH5-k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apliquemos el preprocesamiento para este dataset:"
      ],
      "metadata": {
        "id": "p5bajmLh5Mnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"M√°ximo valor de X_train: {np.max(X_train)}\")\n",
        "print(f\"M√≠nimo valor de X_train: {np.min(X_train)}\")\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_val = X_val.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "X_train /= 255\n",
        "X_val /= 255\n",
        "X_test /= 255\n",
        "\n",
        "print(f\"M√°ximo valor de X_train: {np.max(X_train)}\")\n",
        "print(f\"M√≠nimo valor de X_train: {np.min(X_train)}\")"
      ],
      "metadata": {
        "id": "K2j_drw-o2Cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizamos 6 ejemplos aleatorios, junto con sus etiquetas"
      ],
      "metadata": {
        "id": "aMaXApsBWk4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ------ Obtenemos algunos √≠ndices aleatorios:\n",
        "some_idxs = np.random.choice(list(range(y_train.shape[0])),size=6,replace=False)\n",
        "\n",
        "fig, axes = plt.subplots(ncols=6, sharex=False,\n",
        "\t\t\t sharey=True, figsize=(10, 4))\n",
        "for i,idx in enumerate(some_idxs):\n",
        "\taxes[i].set_title(y_train[idx],fontsize=15)\n",
        "\taxes[i].imshow(X_train[idx], cmap='gray')\n",
        "\taxes[i].get_xaxis().set_visible(False)\n",
        "\taxes[i].get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bUTt4ZizVYwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definiendo la red"
      ],
      "metadata": {
        "id": "mW1Z8KJlcrzo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Etiqueta de clase vs Vector de clase\n",
        "\n",
        "**IMPORTANTE‚ùó**\n",
        "\n",
        "Al usar redes neuronales, usalmente el vector de etiquetas debe estar codificado como vectores **one-hot**. Es decir:\n",
        "\n",
        "$$1 ‚Üí (1,0,...,0) $$\n",
        "$$2 ‚Üí (0,1,...,0) $$\n",
        "$$ ... $$\n",
        "\n",
        "Entonces, las etiquetas $y$ son matrices de tama√±o $N\\times m$ donde\n",
        "\n",
        "* $N$: n√∫mero de instancias\n",
        "* $m$: n√∫mero de clases\n",
        "\n",
        "\n",
        "\n",
        "Hacemos la codificaci√≥n usando la funci√≥n [`to_categorical`](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical) de [keras](https://www.tensorflow.org/guide/keras).\n",
        "\n",
        "$$y_j \\overset{\\text{to_categorical}}{\\rightarrow} (0,...,0,\\overset{j}{1},0,...,0)$$\n",
        "\n",
        "$$y_j \\overset{\\text{numpy.argmax}}{\\leftarrow} (0,...,0,\\overset{j}{1},0,...,0)$$\n",
        "\n",
        "‚ö† A lo largo de las versiones, a veces cambia de ubicaci√≥n este tipo de funciones.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LhgR_BXxQh1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "print(\"---------- Antes de la codificaci√≥n ----------\")\n",
        "print(f\"Primeras 5 etiquetas: {y_train[:5]}\")\n",
        "print(f\"Shape: {y_train.shape}\")\n",
        "\n",
        "y_train = to_categorical(y_train,num_classes=10)\n",
        "\n",
        "print(\"---------- Despu√©s de la codificaci√≥n ----------\")\n",
        "print(f\"Primeras 5 etiquetas:\\n{y_train[:5]}\\n\")\n",
        "print(f\"Shape: {y_train.shape}\")\n",
        "\n",
        "y_val = to_categorical(y_val,num_classes=10)\n",
        "y_test = to_categorical(y_test,num_classes=10)"
      ],
      "metadata": {
        "id": "e6m0Lsa287SE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ingredientes de una arquitectura"
      ],
      "metadata": {
        "id": "PX0WLYf7EFz0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hay dos principales maneras de definir modelos en Keras:\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1lbLQ7D1_QElq_iTscpQ_rjXPWJ2uPke3\" width=500>\n",
        "</center>\n",
        "\n",
        "\n",
        "* [**Sequential**](https://keras.io/api/models/sequential/): Un modelo es una secuencia lineal de *layers*. Es sencilla de implementar pero no muy flexible.\n",
        "\n",
        "\n",
        "* [**Model**](https://www.tensorflow.org/api_docs/python/tf/keras/Model): Un modelo se especifica mediante una estructura similar a un *grafo*, indicando conexiones entre *layers*. Es muy flexible.\n",
        "\n"
      ],
      "metadata": {
        "id": "0zb07-KDEVuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential"
      ],
      "metadata": {
        "id": "QP-kmKm8Ifn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por ahora, usaremos los siguientes tipos b√°sicos de capas:\n",
        "\n",
        "* [**Dense**](https://keras.io/api/layers/core_layers/dense/): implementa la operaci√≥n:\n",
        "$$\\text{output} = \\text{activation}(\\text{input}\\cdot\\text{weights} + \\text{bias})$$\n",
        "donde `activation` es la funci√≥n de activaci√≥n y bias es un vector de sesgo creado por la capa (s√≥lo aplicable si `use_bias` es True). Es una capa **densa** por lo que cada neurona de esta capa se conecta con cada una de las neuronas de la capa anterior.\n",
        "* [**Flatten**](https://keras.io/api/layers/reshaping_layers/flatten/): Aplana los datos para tener un arreglo unidimensional.\n",
        "* [**Input**](https://keras.io/api/layers/core_layers/input/): Define el tensor de entrada de la red con su forma. Es el punto de entrada para los datos en el modelo."
      ],
      "metadata": {
        "id": "4d6agAfTRbbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense, Flatten, Input"
      ],
      "metadata": {
        "id": "rACJOLUmVPKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos ahora la arquitectura de la red neuronal MLP. Observa los siguientes elementos:\n",
        "\n",
        "* La **funci√≥n de activaci√≥n** de cada capa, [documentaci√≥n](https://keras.io/api/layers/activations/).\n",
        "* La **funci√≥n de perdida** de la red, es la funci√≥n de costo que mide que tanto error hay en las predicciones. El optimizador minimizar√° est√° funci√≥n, [documentaci√≥n](https://keras.io/api/losses/).\n",
        "* El **optimizador** es la clase que minimizar√° la funci√≥n de perdida. De su elecci√≥n depende qu√© tan r√°pido converjamos a una soluci√≥n, [documentaci√≥n](https://keras.io/api/optimizers/)\n",
        "* La(s) **m√©trica(s) de desempe√±o** a monitorear durante el entrenamiento, tanto en el conjunto de entrenamiento como en el de validaci√≥n. Adem√°s, podemos evaluar las m√©tricas usuales al generar las predicciones. [Documentaci√≥n](https://keras.io/api/metrics/)"
      ],
      "metadata": {
        "id": "buR2gumKxqlB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Input\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(28,28)))\n",
        "model.add(Flatten()) # Tenemos que aplanar las matrices representando a cada imagen, las capas densas s√≥lo funcionan con vectores de entrada\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))  # Cuando se trata de tareas de clasificaci√≥n multiclase, ponemos una activaci√≥n softmax en la capa de salida"
      ],
      "metadata": {
        "id": "60jIjz2c9gpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "oJxIalpahBnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El m√©todo `summary()` de un modelo de Keras (ya sea `Sequential` o `Model`) imprime informaci√≥n importante del modelo. [Documentaci√≥n](https://keras.io/api/models/model/)."
      ],
      "metadata": {
        "id": "mNqfxHgeiRA9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El siguiente paso es compilar el modelo. Esto lo hacemos con el m√©todo [`compile`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile).\n",
        "\n",
        "---\n",
        "\n",
        "Una gu√≠a general sobre funciones de perdida y m√©tricas\n",
        "\n",
        "| Aplicaci√≥n                     | Funci√≥n de P√©rdida (Loss)          | M√©trica usual           | √öltima capa (output layer)          |\n",
        "|---------------------------------|------------------------------------|-------------------------|-------------------------------------|\n",
        "| Clasificaci√≥n binaria          | `binary_crossentropy`              | `accuracy`              | `Dense(1, activation='sigmoid')`    |\n",
        "| Clasificaci√≥n multiclase       | `categorical_crossentropy`         | `accuracy`              | `Dense(num_clases, activation='softmax')` |\n",
        "| Regresi√≥n (un valor)           | `mean_squared_error` (MSE)         | `mse` o `mae`           | `Dense(1, activation='linear')`     |\n",
        "| Regresi√≥n (m√∫ltiples valores)  | `mean_squared_error` (MSE)         | `mse` o `mae`           | `Dense(num_valores, activation='linear')` |\n",
        "\n",
        "Una gu√≠a general sobre optimizadores:\n",
        "\n",
        "| Optimizador  | Ventajas                             | Casos de Uso T√≠picos         | Par√°metros Clave               |\n",
        "|--------------|--------------------------------------|------------------------------|--------------------------------|\n",
        "| **Adam**     | Convergencia r√°pida, adaptable      | Default para MLPs, CNN, RNN  | `lr`  |\n",
        "| **SGD**      | Mayor control, estable con momentum | Problemas convexos, fine-tuning | `lr`, `momentum`      |\n",
        "| **RMSprop**  | Bueno para datos ruidosos           | RNNs, problemas inestables    | `lr`, `rho`          |\n",
        "\n",
        "---\n",
        "\n",
        "‚ö† ‚ùó **IMPORTANTE** Antes de volver a entrenar un modelo, **debes recompilarlo** con el m√©todo `compile()`. Esto reinicializa los pesos aleatoriamente y evita que el entrenamiento contin√∫e desde los pesos previamente aprendidos.  "
      ],
      "metadata": {
        "id": "Px0VQcJGftdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "\t      optimizer='adam',\n",
        "\t      metrics=['acc']\n",
        "\t\t  )"
      ],
      "metadata": {
        "id": "okXXQBa8f1X0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenando la red"
      ],
      "metadata": {
        "id": "SCWhDOIhcx6V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenamos la red con el m√©todo [`fit`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit), la m√©canica es la misma que en los m√©todos de ML cl√°sico.\n",
        "\n",
        "Algunas diferencias son:\n",
        "\n",
        "* Especificar el n√∫mero de √©pocas. Entre m√°s √©pocas, m√°s puede aprender el m√≥delo, aunque hay m√°s riesgo de overfitting.\n",
        "\n",
        "* Especificar el conjunto de validaci√≥n, adem√°s del conjunto de entrenamiento. Este sirve para proporcionar un indicador no sesgado del desempe√±o del modelo. Se puede hacer especificamente, o como una fracci√≥n del conjunto de entrenamiento.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uFawgzy6iQBO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observa las m√©tricas y p√©rdida en el conjunto de entrenamiento y validaci√≥n.\n",
        "\n",
        "El entrenamiento regresa un objeto de tipo `History`. Su atributo History.history es un registro de valores de p√©rdidas de entrenamiento y valores de m√©tricas en √©pocas sucesivas, as√≠ como valores de p√©rdidas de validaci√≥n y valores de m√©tricas de validaci√≥n (si procede)."
      ],
      "metadata": {
        "id": "HiGm_48QijLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_epocas = 8\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=n_epocas, validation_data=(X_val,y_val))"
      ],
      "metadata": {
        "id": "AiR8OwXtcxlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graficamos la funci√≥n de perdida en cada √©poca, tanto en el conjunto de entrenamiento, como en el de validaci√≥n.\n",
        "\n",
        "Estas se llaman **gr√°ficas de entrenamiento**. Son muy importantes para evaluar si hay overfitting, entre otras cosas.\n",
        "\n",
        "Observa que los registros *hist√≥ricos* del entrenamiento (perdidas y m√©tricas) se encuentran en el diccionario `history.history` especificado anteriormente."
      ],
      "metadata": {
        "id": "W_gbtP6biie8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_train = history.history['loss']\n",
        "loss_val = history.history['val_loss']\n",
        "acc_train = history.history['acc']\n",
        "acc_val = history.history['val_acc']\n",
        "\n",
        "epochs = range(1,n_epocas+1)\n",
        "\n",
        "fig, axs = plt.subplots(1,2,figsize=(12,5))\n",
        "axs[0].plot(epochs, loss_train, 'g', label='Training loss')\n",
        "axs[0].plot(epochs, loss_val, 'b', label='validation loss')\n",
        "axs[0].title.set_text('Loss')\n",
        "axs[0].set(xlabel=\"√âpoca\", ylabel=\"Loss\")\n",
        "axs[0].legend()\n",
        "axs[1].plot(epochs, acc_train, 'g', label='Training accuracy')\n",
        "axs[1].plot(epochs, acc_val, 'b', label='validation accuracy')\n",
        "axs[1].title.set_text('Accuracy')\n",
        "axs[1].set(xlabel=\"√âpoca\", ylabel=\"Accuracy\")\n",
        "axs[1].legend()\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "kxTBG2maTJ8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîµ ¬øHay se√±ales de overfitting? ¬øunderfitting?"
      ],
      "metadata": {
        "id": "HU4pE_eFe4Wd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚ö° De la siguiente forma podemos acceder a la matriz de pesos y sesgos en cada capa. Las guardamos como arreglos de numpy."
      ],
      "metadata": {
        "id": "il-DfAt8iaAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_layer_weights = model.layers[1].get_weights()[0]\n",
        "first_layer_biases  = model.layers[1].get_weights()[1]\n",
        "\n",
        "np.save(\"mnist_weights1.npy\",first_layer_weights)\n",
        "np.save(\"mnist_biases1.npy\",first_layer_biases)"
      ],
      "metadata": {
        "id": "gBNBoNKvVBqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "second_layer_weights = model.layers[2].get_weights()[0]\n",
        "second_layer_biases  = model.layers[2].get_weights()[1]\n",
        "\n",
        "np.save(\"mnist_weights2.npy\",second_layer_weights)\n",
        "np.save(\"mnist_biases2.npy\",second_layer_biases)"
      ],
      "metadata": {
        "id": "vdfwdS6HWQXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predicciones y rendimiento"
      ],
      "metadata": {
        "id": "_qz0K0NOIyFy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîΩ ¬øC√≥mo se ven las predicciones?"
      ],
      "metadata": {
        "id": "aGZMU7s6Xr30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from seaborn import heatmap\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ----- Escogemos un elemento del conjunto test:\n",
        "idx = np.random.choice(range(X_test.shape[0]),size=1)[0]\n",
        "print(f\"√≠ndice test: {idx}\")\n",
        "x = X_test[idx].copy()\n",
        "\n",
        "# ----- Graficamos este ejemplo de prueba:\n",
        "plt.figure()\n",
        "plt.suptitle(y_test_original[idx],fontsize=15)\n",
        "plt.imshow(x, cmap='gray')\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.show()\n",
        "\n",
        "# ----- Cambiamos a la forma adecuada para entrar a la red neuronal:\n",
        "x_input = x.reshape(-1,x.shape[0],x.shape[1])\n",
        "\n",
        "# ----- Lo pasamos por la red neuronal ya entrenada:\n",
        "prediction = model.predict(x_input)\n",
        "print(f\"\\nSalida de la red neuronal para este elemento:\")\n",
        "\n",
        "plt.figure(figsize=(5,1))\n",
        "heatmap(prediction, cmap='plasma',annot=np.round(prediction,2),cbar=False)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.show()\n",
        "\n",
        "print(f\"Son probabilidades, la suma de las entradas es {np.sum(prediction)}\")\n",
        "\n",
        "# ----- Tomamos el argmax:\n",
        "prediction = np.argmax(prediction, axis=1)\n",
        "print(f\"\\nTomamos el √≠ndice de la entrada con mayor probabilidad: {prediction}\")"
      ],
      "metadata": {
        "id": "FnIT0a9oXpWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtenemos todas las predicciones sobre el conjunto de prueba."
      ],
      "metadata": {
        "id": "sZGUKuY5aFWV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_matrix = model.predict(X_test,batch_size=1)  # Observa el batch_size\n",
        "predictions = np.argmax(predictions_matrix, axis=1)  # Prueba a comentar esta l√≠nea y discutamos qu√© pasa"
      ],
      "metadata": {
        "id": "x0YY_HBa9jAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizamos algunas predicciones"
      ],
      "metadata": {
        "id": "HlXiyLiGaLJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idxs = np.random.choice(range(X_test.shape[0]),size=10,replace=False)\n",
        "\n",
        "fig, axes = plt.subplots(ncols=10, sharex=False,\n",
        "\t\t\t sharey=True, figsize=(18, 4))\n",
        "for i,idx in enumerate(idxs):\n",
        "\taxes[i].set_title(predictions[idx])\n",
        "\taxes[i].imshow(X_test[idx], cmap='gray')\n",
        "\taxes[i].get_xaxis().set_visible(False)\n",
        "\taxes[i].get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "daQYjWh99iq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtenemos las m√©tricas de desempe√±o de la tarea de clasificaci√≥n. Observar que ambas son **vectores** de etiquetas"
      ],
      "metadata": {
        "id": "1cUoiJrvir5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions.shape)\n",
        "print(y_test_original.shape)"
      ],
      "metadata": {
        "id": "WCz6DqTG7vwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy_score(y_pred=predictions,y_true=y_test_original)}\")\n",
        "print(f\"Test Recall: {recall_score(y_pred=predictions,y_true=y_test_original,average='macro')}\")\n",
        "print(f\"Test Precision: {precision_score(y_pred=predictions,y_true=y_test_original,average='macro')}\")"
      ],
      "metadata": {
        "id": "GxxW6UUA9qP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculamos el roc-auc score"
      ],
      "metadata": {
        "id": "15IH0ptN_HJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "print(f\"Shape de y_test: {y_test.shape}\")\n",
        "print(f\"Shape de las predicciones para el conjunto de prueba: {predictions_matrix.shape}\")\n",
        "\n",
        "ra_score = roc_auc_score(y_test,predictions_matrix)\n",
        "print(f\"ROC-AUC score {ra_score}\")"
      ],
      "metadata": {
        "id": "CGdLt3Jq-hDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mostramos la matriz de confusi√≥n"
      ],
      "metadata": {
        "id": "7ZCs1TCsiwr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "cm = confusion_matrix(y_test_original,predictions)\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L24mC3bcO0AD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚≠ï ¬øQu√© d√≠gitos son los que m√°s confunde la red?"
      ],
      "metadata": {
        "id": "XebS2v79iy74"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La diferencia entre las m√©tricas de clasificaci√≥n (accuracy, precision, recall) y el ROC-AUC radica en lo que cada una eval√∫a. Las m√©tricas de clasificaci√≥n miden el rendimiento del modelo con un umbral de decisi√≥n fijo, t√≠picamente 0.5 para clasificaci√≥n binaria o el valor m√°ximo de probabilidad para multiclase. En contraste, el ROC-AUC eval√∫a la capacidad del modelo para distinguir entre clases a trav√©s de todos los posibles umbrales de decisi√≥n. Un modelo puede tener un ROC-AUC alto porque ordena correctamente las muestras seg√∫n su probabilidad de pertenencia a cada clase, pero mostrar m√©tricas de clasificaci√≥n moderadas porque las probabilidades predichas no est√°n calibradas para el umbral de decisi√≥n utilizado. Esta discrepancia indica que el modelo posee buena capacidad discriminativa pero requiere optimizaci√≥n del umbral de decisi√≥n o calibraci√≥n de probabilidades para maximizar su rendimiento en la clasificaci√≥n final."
      ],
      "metadata": {
        "id": "CGRooKhQRjXX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üîΩ Predicci√≥n en el mundo real\n",
        "\n",
        "Observa que este modelo est√° listo para hacer predicciones en el *mundo real*. Carguemos algunas imagenes de d√≠gitos hechos por t√≠:\n",
        "\n",
        "* Escribe un d√≠gito en una hoja\n",
        "* T√≥male foto\n",
        "* Guardalo como imagen png\n",
        "* S√∫bela a colab\n",
        "* Ejecuta la celda siguiente con las modificaciones pertinentes"
      ],
      "metadata": {
        "id": "GkOOiinlg8o-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def procesar_imagen(ruta_imagen):\n",
        "    img = Image.open(ruta_imagen) # Leer la imagen\n",
        "    img_gris = img.convert('L') # Convertir a escala de grises\n",
        "    img_28x28 = img_gris.resize((28, 28),\n",
        "                                # Image.Resampling.LANCZOS\n",
        "                                ) # Redimensionar a 28x28 p√≠xeles\n",
        "    arreglo = np.array(img_28x28, dtype=int) # Convertir a arreglo NumPy\n",
        "    arreglo = np.clip(arreglo, 0, 255) # Asegurar que los valores est√°n en 0-255\n",
        "    return arreglo\n",
        "\n",
        "\n",
        "ruta = '/content/digito0.jpeg'  # Cambia por tu ruta\n",
        "\n",
        "arreglo_28x28 = procesar_imagen(ruta)\n",
        "arreglo_28x28 = 255 - arreglo_28x28  # Invierte colores\n",
        "arreglo_28x28 = arreglo_28x28.astype('int')/255\n",
        "\n",
        "plt.figure(figsize=(4,4))\n",
        "plt.imshow(arreglo_28x28, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ojpNi9dYg8dv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(arreglo_28x28)"
      ],
      "metadata": {
        "id": "97ur0wVDi_GY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediccion = model.predict(arreglo_28x28.reshape(-1,28,28))\n",
        "np.argmax(prediccion)"
      ],
      "metadata": {
        "id": "2XPP86BdiVUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## ‚≠ï Pr√°ctica y Ejercicios\n",
        "\n",
        "En esta pr√°ctica vamos a definir, compilar y entrenar varias arquitecturas de redes neuronales\n",
        "\n",
        "Implementa las siguientes redes neuronales de tipo MLP:\n",
        "\n",
        "* 1 capa oculta de 200 neuronas sin activaci√≥n. Entrena durante 30 √©pocas.\n",
        "* 1 capa oculta de 200 neuronas con activaci√≥n $tanh$. Entrena durante 30 √©pocas.\n",
        "* 3 capas ocultas de 100, 200 y 100 neuronas respectivamente, todas con activaci√≥n ReLU. Entrena durante 50 √©pocas.\n",
        "\n",
        "En cada uno de los experimentos determina las especificaciones de las capas de entrada y salida. Adem√°s, en cada caso, reporta el accuracy y recall en el conjunto de prueba, as√≠ como las curvas de entrenamiento (perdida y accuracy).\n",
        "\n",
        "* Con el objetivo de subir la m√©trica de accuracy en el conjunto de prueba, entrena un nuevo m√≥delo de red neuronal MLP cambiando los siguientes hiperpar√°metros:\n",
        "\n",
        " * N√∫mero de capas ocultas.\n",
        " * N√∫mero de neuronas en cada capa oculta.\n",
        " * Funci√≥n de activaci√≥n de cada capa oculta.\n",
        " * Optimizador ([opciones](https://keras.io/api/optimizers/)).\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Como referencia, el mejor resultado hasta ahora, sin usar redes convolucionales, es un accuracy de 99.65% (https://arxiv.org/abs/1003.0358)\n",
        "\n",
        "Lista de resultados: http://yann.lecun.com/exdb/mnist/, https://paperswithcode.com/sota/image-classification-on-mnist"
      ],
      "metadata": {
        "id": "vDSCKhUMkOUL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "476YuSzUohvT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üü¢ Descargamos el conjunto de datos y preprocesamiento"
      ],
      "metadata": {
        "id": "C0uSyZVTX80C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense, Flatten\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,\n",
        "                                                  test_size=0.15,\n",
        "                                                  stratify=y_train,\n",
        "                                                  random_state=782)\n",
        "\n",
        "X_train = X_train.astype('float32')/255\n",
        "X_val = X_val.astype('float32')/255\n",
        "X_test = X_test.astype('float32')/255\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"X_val shape: {X_val.shape}\")\n",
        "print(f\"y_val shape: {y_val.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")\n",
        "\n",
        "\n",
        "y_test_original = y_test.copy()\n",
        "y_train = to_categorical(y_train,num_classes=10)\n",
        "y_val = to_categorical(y_val,num_classes=10)\n",
        "y_test = to_categorical(y_test,num_classes=10)"
      ],
      "metadata": {
        "id": "uDnEB9WX8m8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define una arquitectura con una capa oculta de 200 neuronas, con activaci√≥n `tanh`"
      ],
      "metadata": {
        "id": "WckUKa5QYYlY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Input\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(28,28)))\n",
        "model.add(Flatten())\n",
        "\n",
        "# a√±ade la capa oculta:\n",
        "\n",
        "\n",
        "# ---------------\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Imprimimos el summary:\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "fYF4ustEYUtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî¥ Compila el modelo con la misma funci√≥n de perdida, m√©trica y optimzador"
      ],
      "metadata": {
        "id": "lvGvrGwSZy4T"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nOzzcuK_Z2Qi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî¥ Entrena el modelo en el conjunto de entrenamiento, usa el conjunto `X_val, y_val` como validaci√≥n. Entrena durante 15 √©pocas."
      ],
      "metadata": {
        "id": "XFd6B3X3Z2dq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "czVlhvQZOQ_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üü¢ Graficamos la p√©rdida y m√©trica durante el entrenamiento, ¬øobservas overfitting o underfitting?"
      ],
      "metadata": {
        "id": "YRvIE3waO9Zb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_train = history.history['loss']\n",
        "loss_val = history.history['val_loss']\n",
        "acc_train = history.history['acc']\n",
        "acc_val = history.history['val_acc']\n",
        "\n",
        "epochs = range(1,n_epocas+1)\n",
        "\n",
        "fig, axs = plt.subplots(1,2,figsize=(12,5))\n",
        "axs[0].plot(epochs, loss_train, 'g', label='Training loss')\n",
        "axs[0].plot(epochs, loss_val, 'b', label='validation loss')\n",
        "axs[0].title.set_text('Loss')\n",
        "axs[0].set(xlabel=\"√âpoca\", ylabel=\"Loss\")\n",
        "axs[0].legend()\n",
        "axs[1].plot(epochs, acc_train, 'g', label='Training accuracy')\n",
        "axs[1].plot(epochs, acc_val, 'b', label='validation accuracy')\n",
        "axs[1].title.set_text('Accuracy')\n",
        "axs[1].set(xlabel=\"√âpoca\", ylabel=\"Accuracy\")\n",
        "axs[1].legend()\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "_5sL06wPO9Gc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî¥ Obten las predicciones y evalua el desempe√±o del modelo usando F1-score y Accuracy. Imprime ambas m√©tricas"
      ],
      "metadata": {
        "id": "LW3WaLK2SJAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "predictions_matrix = ...\n",
        "y_pred = np.argmax(predictions_matrix, axis=1)\n",
        "\n",
        "accuracy = ...\n",
        "f1score = ..."
      ],
      "metadata": {
        "id": "0HWXsHLySI2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî¥ En una sola celda, define una red MLP con las siguientes especificaciones:\n",
        "\n",
        "* Capa de entrada (indica el `shape` adecuado)\n",
        "* Capa Flatten\n",
        "* Capa Oculta Densa de 200 neuronas, activaci√≥n `relu`\n",
        "* Capa Oculta Densa de 500 neuronas, activaci√≥n `tanh`\n",
        "* Capa Oculta Densa de 200 neuronas, activaci√≥n `relu`\n",
        "* Capa de Salida adecuada con activaci√≥n adecuada\n",
        "\n",
        "El resto de pasos como el ejercicio anterior.\n"
      ],
      "metadata": {
        "id": "5LcPO9HrTe74"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DyZWUO79TesO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Soluci√≥n: Un mejor modelo\n",
        "\n"
      ],
      "metadata": {
        "id": "XohNww6KYNg3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuaci√≥n se muestra una soluci√≥n con un modelo entrenado previamente:"
      ],
      "metadata": {
        "id": "kk3G1vS_XfnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# URL del archivo raw en GitHub\n",
        "url = \"https://github.com/DCDPUAEM/DCDP/raw/main/04%20Deep%20Learning/data/mejor_modelo_mlp.h5\"\n",
        "\n",
        "# Descargar el archivo usando wget\n",
        "!wget {url}"
      ],
      "metadata": {
        "id": "m3pkWR-KYmfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "# Cargar el modelo\n",
        "mejor_modelo = keras.models.load_model('mejor_modelo_mlp.h5')\n",
        "\n",
        "# Ver arquitectura del modelo entrenado y cargado\n",
        "print(\"=== Resumen del modelo ===\")\n",
        "mejor_modelo.summary()"
      ],
      "metadata": {
        "id": "nyeP4o8RTrJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediccion = mejor_modelo.predict(X_test.reshape(-1,28*28))\n",
        "y_pred = np.argmax(prediccion, axis=1)\n",
        "print(y_pred[:10])"
      ],
      "metadata": {
        "id": "7IX973xfTzpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "from seaborn import heatmap\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = confusion_matrix(y_test_original,y_pred)\n",
        "plt.figure()\n",
        "heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.show()\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy_score(y_pred=y_pred,y_true=y_test_original)}\")\n",
        "print(f\"Test F1-score: {f1_score(y_pred=y_pred,y_true=y_test_original,average='macro')}\")"
      ],
      "metadata": {
        "id": "KhYOWA71UJdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/gmauricio-toledo/matematicas-aprendizaje-automatico/raw/main/Galer√≠a/digito.jpeg"
      ],
      "metadata": {
        "id": "SdqZI17cUyb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def procesar_imagen(ruta_imagen):\n",
        "    img = Image.open(ruta_imagen) # Leer la imagen\n",
        "    img_gris = img.convert('L') # Convertir a escala de grises\n",
        "    img_28x28 = img_gris.resize((28, 28),\n",
        "                                # Image.Resampling.LANCZOS\n",
        "                                ) # Redimensionar a 28x28 p√≠xeles\n",
        "    arreglo = np.array(img_28x28, dtype=int) # Convertir a arreglo NumPy\n",
        "    arreglo = np.clip(arreglo, 0, 255) # Asegurar que los valores est√°n en 0-255\n",
        "    return arreglo\n",
        "\n",
        "\n",
        "ruta = '/content/digito.jpeg'  # Cambia por tu ruta\n",
        "\n",
        "arreglo_28x28 = procesar_imagen(ruta)\n",
        "arreglo_28x28 = 255 - arreglo_28x28  # Invierte colores\n",
        "arreglo_28x28 = arreglo_28x28.astype('int')/255\n",
        "\n",
        "plt.figure(figsize=(4,4))\n",
        "plt.imshow(arreglo_28x28, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5mdxHFeEUjU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediccion = mejor_modelo.predict(arreglo_28x28.reshape(-1,28*28))\n",
        "print(f\"Clase predicha: {np.argmax(prediccion)}\")"
      ],
      "metadata": {
        "id": "aL4Qy21bT82h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}